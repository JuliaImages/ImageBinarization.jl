var documenterSearchIndex = {"docs":
[{"location":"reference/#function_reference","page":"Function Reference","title":"Function References","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"Pages = [\"reference.md\"]\nDepth = 3","category":"page"},{"location":"reference/#General-function","page":"Function Reference","title":"General function","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"binarize\nbinarize!","category":"page"},{"location":"reference/#ImageBinarization.BinarizationAPI.binarize","page":"Function Reference","title":"ImageBinarization.BinarizationAPI.binarize","text":"binarize([T::Type,] img, f::AbstractImageBinarizationAlgorithm, args...; kwargs...)\n\nBinarize img using algorithm f.\n\nOutput\n\nThe return image img₀₁ is an Array{T}.\n\nIf T is not specified, then it's inferred as Gray{eltype(eltype(img))}, which is Gray{N0f8} for img of type Array{N0f8} and Array{Gray{N0f8}}, and Gray{Float32} for img of type Array{Float32} and Array{Gray{Float32}}\n\nExamples\n\nJust simply pass the input image and algorithm to binarize\n\nimg₀₁ = binarize(img, f)\n\nThis reads as \"binarize image img using binarization algorithm f\".\n\nYou can also explicitly specify the return type:\n\nimg₀₁_float32 = binarize(Gray{Float32}, img, f)\n\nSee also binarize! for in-place binarization.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ImageBinarization.BinarizationAPI.binarize!","page":"Function Reference","title":"ImageBinarization.BinarizationAPI.binarize!","text":"binarize!([out,] img, f::AbstractImageBinarizationAlgorithm, args...; kwargs...)\n\nBinarize img using algorithm f.\n\nOutput\n\nIf out is specified, it will be changed in place. Otherwise img will be changed in place.\n\nExamples\n\nJust simply pass an algorithm to binarize!:\n\nimg₀₁ = similar(img)\nbinarize!(img₀₁, img, f)\n\nFor cases you just want to change img in place, you don't necessarily need to manually allocate img₀₁; just use the convenient method:\n\nbinarize!(img, f)\n\nSee also: binarize\n\n\n\n\n\n","category":"function"},{"location":"reference/#Algorithms","page":"Function Reference","title":"Algorithms","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"ImageBinarization.BinarizationAPI.AbstractImageBinarizationAlgorithm","category":"page"},{"location":"reference/#ImageBinarization.BinarizationAPI.AbstractImageBinarizationAlgorithm","page":"Function Reference","title":"ImageBinarization.BinarizationAPI.AbstractImageBinarizationAlgorithm","text":"AbstractImageBinarizationAlgorithm <: AbstractImageFilter\n\nThe root type for ImageBinarization package.\n\nAny concrete binarization algorithm shall subtype it to support binarize and binarize! APIs.\n\nExamples\n\nAll algorithms in ImageBinarization are called in the following pattern:\n\n# first generate an algorithm instance\nf = Otsu()\n\n# then pass the algorithm to `binarize`\nimg₀₁ = binarize(img, f) # `eltype(img₀₁)` is `Gray{N0f8}`\n\n# or use in-place version `binarize!`\nimg₀₁ = similar(img)\nbinarize!(img₀₁, img, f)\n\nSome algorithms also receive additional information of image as an argument to infer the \"best\" parameters, e.g., window_size of AdaptiveThreshold.\n\n# you could explicit specify the it\nf = AdaptiveThreshold(window_size = 32)\n\n# or infer the \"best\" default value from given image\nimg = testimage(\"cameraman\")\nf = AdaptiveThreshold(img)\n\nFor more examples, please check binarize and binarize! and concret algorithms.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Adaptive-Threshold","page":"Function Reference","title":"Adaptive Threshold","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"AdaptiveThreshold","category":"page"},{"location":"reference/#ImageBinarization.AdaptiveThreshold","page":"Function Reference","title":"ImageBinarization.AdaptiveThreshold","text":"AdaptiveThreshold <: AbstractImageBinarizationAlgorithm\nAdaptiveThreshold([img]; [window_size,] percentage = 15)\n\nbinarize([T,] img, f::AdaptiveThreshold)\nbinarize!([out,] img, f::AdaptiveThreshold)\n\nBinarize img using a threshold that varies according to background illumination.\n\nOutput\n\nReturn the binarized image as an Array{Gray{T}} of size size(img). If T is not specified, it is inferred from out and img.\n\nExtended help\n\nDetails\n\nIf the value of a pixel is t percent less than the average of an s times s window of pixels centered around the pixel, then the pixel is set to black, otherwise it is set to white.\n\nA computationally efficient method for computing the average of an s times s neighbourhood is achieved by using an integral image integral_image.\n\nThis algorithm works particularly well on images that have distinct contrast between background and foreground. See [1] for more details.\n\nArguments\n\nThe function argument is described in more detail below.\n\nimg::AbstractArray\n\nThe image that need to be binarized. The image is automatically converted to Gray in order to construct the requisite graylevel histogram.\n\nYou can also pass img to AdaptiveThreshold to automatically infer the \"best\" window_size.\n\nOptions\n\nVarious options for the parameters of AdaptiveThreshold, binarize and binarize! are described in more detail below.\n\nChoices for percentage\n\nYou can specify an integer for the percentage (denoted by t in [1]) which must be between 0 and 100. Default: 15\n\nChoices for window_size\n\nThe argument window_size (denoted by s in [1]) specifies the size of pixel's square neighbourhood which must be greater than zero.\n\nIf img is passed to AdaptiveThreshold constructor, then window_size is infered as the integer closest to 1/8 of the average of the width and height of img.\n\nExamples\n\nusing TestImages\n\nimg = testimage(\"cameraman\")\nf = AdaptiveThreshold(window_size = 16)\nimg₀₁ = binarize(img, f)\n\nf = AdaptiveThreshold(img) # infer the best `window_size` using `img`\nimg₀₁ = binarize(img, f)\n\nSee also binarize! for in-place operation.\n\nReferences\n\n[1] Bradley, D. (2007). Adaptive Thresholding using Integral Image. Journal of Graphic Tools, 12(2), pp.13-21. doi:10.1080/2151237x.2007.10129236\n\n\n\n\n\n","category":"type"},{"location":"reference/#Niblack","page":"Function Reference","title":"Niblack","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"Niblack","category":"page"},{"location":"reference/#ImageBinarization.Niblack","page":"Function Reference","title":"ImageBinarization.Niblack","text":"Niblack <: AbstractImageBinarizationAlgorithm\nNiblack(; window_size = 7, bias = 0.2)\n\nbinarize([T,] img, f::Niblack)\nbinarize!([out,] img, f::Niblack)\n\nApplies Niblack adaptive thresholding [1] under the assumption that the input image is textual.\n\nOutput\n\nReturn the binarized image as an Array{Gray{T}} of size size(img). If T is not specified, it is inferred from out and img.\n\nExtended help\n\nDetails\n\nThe input image is binarized by varying the threshold across the image, using a modified version of Niblack's algorithm [2]. A threshold T is defined for each pixel based on the mean m and standard deviation s of the intensities of neighboring pixels in a window around it. This threshold is given by\n\nT(xy) = m(xy) + k cdot s(xy)\n\nwhere k is a user-defined parameter weighting the influence of the standard deviation on the value of T.\n\nNote that Niblack's algorithm is highly sensitive to variations in the gray values of background pixels, which often exceed local thresholds and appear as artifacts in the binarized image. The Sauvola algorithm included in this package implements an attempt to address this issue [2].\n\nArguments\n\nimg\n\nAn image which is binarized according to a per-pixel adaptive threshold into background (0) and foreground (1) pixel values.\n\nbias::Real  (denoted by k in the publication)\n\nA user-defined biasing parameter on threshold. This can take negative values. Larger bias encourages more black pixels in the output.\n\nwindow_size::Integer (denoted by w in the publication)\n\nThe threshold for each pixel is a function of the distribution of the intensities of all neighboring pixels in a square window around it. The side length of this window is 2w + 1, with the target pixel in the center position.\n\nIf not specified, window_size is 7.\n\nExample\n\nBinarize the \"cameraman\" image in the TestImages package.\n\nusing TestImages, ImageBinarization\n\nimg = testimage(\"cameraman\")\nimg₀₁ = binarize(img, Niblack())\n\nReferences\n\n[1] Wayne Niblack (1986). An Introduction to Image Processing. Prentice-Hall, Englewood Cliffs, NJ: 115-16. [2] J. Sauvola and M. Pietikäinen (2000). \"Adaptive document image binarization\". Pattern Recognition 33 (2): 225-236. doi:10.1016/S0031-3203(99)00055-2\n\n\n\n\n\n","category":"type"},{"location":"reference/#Polysegment","page":"Function Reference","title":"Polysegment","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"Polysegment","category":"page"},{"location":"reference/#ImageBinarization.Polysegment","page":"Function Reference","title":"ImageBinarization.Polysegment","text":"Polysegment <: AbstractImageBinarizationAlgorithm\nPolysegment()\n\nbinarize([T,] img, f::Polysegment)\nbinarize!([out,] img, f::Polysegment)\n\nUses the polynomial segmentation technique to group the image pixels into two categories (foreground and background).\n\nOutput\n\nReturn the binarized image as an Array{Gray{T}} of size size(img). If T is not specified, it is inferred from out and img.\n\nExtended help\n\nDetails\n\nThe approach involves constructing a univariate second-degree polynomial such that the two roots of the polynomial represent the graylevels of two cluster centers (i.e the foreground and background). Pixels are then assigned to the foreground or background depending on which cluster center is closest.\n\nArguments\n\nThe function argument is described in more detail below.\n\nimg::AbstractArray\n\nThe image that needs to be binarized. The image is automatically converted to Gray.\n\nExample\n\nBinarize the \"cameraman\" image in the TestImages package.\n\nusing TestImages, ImageBinarization\n\nimg = testimage(\"cameraman\")\nimg_binary = binarize(img, Polysegment())\n\nReference\n\nR. E. Vidal, \"Generalized Principal Component Analysis (GPCA): An Algebraic Geometric Approach to Subspace Clustering and Motion Segmentation.\" Order No. 3121739, University of California, Berkeley, Ann Arbor, 2003.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Sauvola","page":"Function Reference","title":"Sauvola","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"Sauvola","category":"page"},{"location":"reference/#ImageBinarization.Sauvola","page":"Function Reference","title":"ImageBinarization.Sauvola","text":"Sauvola <: AbstractImageBinarizationAlgorithm\nSauvola(; bias = 0.2, window_size=7)\n\nbinarize([T,] img, f::Sauvola)\nbinarize!([out,] img, f::Sauvola)\n\nApplies Sauvola–Pietikäinen adaptive image binarization [1] under the assumption that the input image is textual.\n\nOutput\n\nReturn the binarized image as an Array{Gray{T}} of size size(img). If T is not specified, it is inferred from out and img.\n\nExtended help\n\nDetails\n\nThe input image is binarized by varying the threshold across the image, using a modified version of Niblack's algorithm [2]. Niblack's approach was to define a threshold T for each pixel based on the mean m and standard deviation s of the intensities of neighboring pixels in a window around it, given by\n\nT(xy) = m(xy) + k cdot s(xy)\n\nwhere k is a user-defined parameter weighting the influence of the standard deviation on the value of T.\n\nNiblack's algorithm is highly sensitive to variations in the gray values of background pixels, which often exceed local thresholds and appear as artifacts in the binarized image. Sauvola and Pietikäinen [1] introduce the dynamic range R of the standard deviation (i.e. its maximum possible value in the color space), such that the threshold is given by\n\nT(xy) = m(xy) cdot left 1 + k cdot left( fracs(xy)R - 1 right) right\n\nThis adaptively amplifies the contribution made by the standard deviation to the value of T.\n\nThe Sauvola–Pietikäinen algorithm is implemented here using an optimization proposed by Shafait, Keysers and Breuel [3], in which integral images are used to calculate the values of m and s for each pixel in constant time. Since each of these data structures can be computed in a single pass over the source image, runtime is significantly improved.\n\nArguments\n\nimg\n\nAn image which is binarized according to a per-pixel adaptive threshold into background (0) and foreground (1) pixel values.\n\nwindow_size::Integer (denoted by w in the publication)\n\nThe threshold for each pixel is a function of the distribution of the intensities of all neighboring pixels in a square window around it. The side length of this window is 2w + 1, with the target pixel in the center position.\n\nbias::Real (denoted by k in the publication)\n\nA user-defined biasing parameter. This can take negative values, though values in the range [0.2, 0.5] are typical. According to [1], this algorithm is not too sensitive to the value of k`.\n\nExample\n\nBinarize the \"cameraman\" image in the TestImages package.\n\nusing TestImages, ImageBinarization\n\nimg = testimage(\"cameraman\")\nimg_binary = binarize(img, Sauvola(window_size = 9, bias = 0.2))\n\nReferences\n\nJ. Sauvola and M. Pietikäinen (2000). \"Adaptive document image binarization\". Pattern Recognition 33 (2): 225-236. doi:10.1016/S0031-3203(99)00055-2\nWayne Niblack (1986). An Introduction to Image Processing. Prentice-Hall, Englewood Cliffs, NJ: 115-16.\nFaisal Shafait, Daniel Keysers and Thomas M. Breuel (2008). \"Efficient implementation of local adaptive thresholding techniques using integral images\". Proc. SPIE 6815, Document Recognition and Retrieval XV, 681510 (28 January 2008). doi:10.1117/12.767755\n\n\n\n\n\n","category":"type"},{"location":"reference/#Algorithms-that-utilizes-single-histogram-threshold","page":"Function Reference","title":"Algorithms that utilizes single histogram-threshold","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"The core functionality of these algorithms are supported by HistogramThresholding.jl","category":"page"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"SingleHistogramThreshold","category":"page"},{"location":"reference/#ImageBinarization.SingleHistogramThreshold","page":"Function Reference","title":"ImageBinarization.SingleHistogramThreshold","text":"SingleHistogramThreshold <: AbstractImageBinarizationAlgorithm\nSingleHistogramThreshold(alg::AbstractThresholdAlgorithm; nbins=256)\n\nbinarize([T,] img, f::AbstractThresholdAlgorithm; nbins=256)\nbinarize!([out,] img, f::AbstractThresholdAlgorithm; nbins=256)\n\nBinarizes the image img using the threshold found by given threshold finding algorithm alg.\n\nOutput\n\nReturn the binarized image as an Array{Gray{T}} of size size(img). If T is not specified, it is inferred from out and img.\n\nArguments\n\nThe function argument is described in more detail below.\n\nimg::AbstractArray\n\nThe image that needs to be binarized.  The image is automatically converted to Gray in order to construct the requisite graylevel histogram.\n\nalg::AbstractThresholdAlgorithm\n\nAbstractThresholdAlgorithm is an abstract type defined in ThresholdAPI.jl in the HistogramThreshold.jl package, it provides various threshold finding algorithms:\n\nHistogramThresholding.Balanced\nHistogramThresholding.Entropy\nHistogramThresholding.Intermodes\nHistogramThresholding.MinimumError\nHistogramThresholding.MinimumIntermodes\nHistogramThresholding.Moments\nHistogramThresholding.Otsu\nHistogramThresholding.UnimodalRosin\nHistogramThresholding.Yen\n\nFor the more detailed explaination and the construction, please refer to each concrete algorithm. For example, type ?Otsu in REPL will give you more details on how to use Otsu methods.\n\nnbins::Integer\n\nThe number of discrete bins that used to build the histogram. A smaller nbins could possibly gives a less noisy, or in other words, a smoother output. The default value is 256.\n\nExamples\n\nAll the usage follows the same pattern, take Otsu as an example:\n\nusing TestImages, ImageBinarization\n\nimg = testimage(\"cameraman\")\nimg_binary = binarize(img, Otsu())\n\nIt is less convenient, but still, you could also construct a SingleHistogramThreshold by yourself:\n\nusing TestImages, ImageBinarization\n\nimg = testimage(\"cameraman\")\nf = SingleHistogramThreshold(Otsu(), nbins=256)\nimg_binary = binarize(img, f)\n\n\n\n\n\n","category":"type"},{"location":"reference/#Otsu","page":"Function Reference","title":"Otsu","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"HistogramThresholding.Otsu","category":"page"},{"location":"reference/#HistogramThresholding.Otsu","page":"Function Reference","title":"HistogramThresholding.Otsu","text":"t = find_threshold(histogram, edges, Otsu())\nt = find_threshold(img, Otsu(); nbins = 256)\n\nUnder the assumption that the histogram is bimodal the threshold is set so that the resultant between-class variance is maximal.\n\nOutput\n\nReturns a real number t in edges. The edges parameter represents an AbstractRange which specifies the intervals associated with the histogram bins.\n\nExtended help\n\nDetails\n\nLet f_i (i=1 ldots I) denote the number of observations in the ith bin of the histogram. Then the probability that an observation belongs to the ith bin is given by  p_i = fracf_iN (i = 1 ldots I), where N = sum_i=1^If_i.\n\nThe choice of a threshold T partitions the data into two categories, C_0 and C_1. Let\n\nP_0(T) = sum_i = 1^T p_i quad textand quad P_1(T) = sum_i = T+1^I p_i\n\ndenote the cumulative probabilities,\n\nmu_0(T) = sum_i = 1^T i fracp_iP_0(T) quad textand quad mu_1(T) = sum_i = T+1^I i fracp_iP_1(T)\n\ndenote the means, and\n\nsigma_0^2(T) = sum_i = 1^T (i-mu_0(T))^2 fracp_iP_0(T) quad textand quad sigma_1^2(T) = sum_i = T+1^I (i-mu_1(T))^2 fracp_iP_1(T)\n\ndenote the variances of categories C_0 and C_1, respectively. Furthermore, let\n\nmu = P_0(T)mu_0(T) + P_1(T)mu_1(T)\n\nrepresent the overall mean,\n\nsigma_b^2(T) = P_0(T)(mu_0(T) - mu)^2 + P_1(T)(mu_1(T) - mu)^2\n\nthe between-category variance, and\n\nsigma_w^2(T) = P_0(T) sigma_0^2(T) +  P_1(T)sigma_1^2(T)\n\nthe within-category variance, respectively.\n\nFinding the discrete value T which maximises the function sigma_b^2(T) produces the sought-after threshold value (i.e. the bin which determines the threshold). As it turns out, that threshold value is equal to the threshold decided by minimizing the within-category variances criterion sigma_w^2(T). Furthermore, that threshold is also the same as the threshold calculated by maximizing the ratio of between-category variance to within-category variance.\n\nArguments\n\nThe function arguments are described in more detail below.\n\nhistogram\n\nAn AbstractArray storing the frequency distribution.\n\nedges\n\nAn AbstractRange specifying how the intervals for the frequency distribution are divided.\n\nExample\n\nCompute the threshold for the \"cameraman\" image in the TestImages package.\n\nusing TestImages, ImageContrastAdjustment, HistogramThresholding\n\nimg = testimage(\"cameraman\")\nedges, counts = build_histogram(img,256)\n#=\n  The `counts` array stores at index 0 the frequencies that were below the\n  first bin edge. Since we are seeking a threshold over the interval\n  partitioned by `edges` we need to discard the first bin in `counts`\n  so that the dimensions of `edges` and `counts` match.\n=#\nt = find_threshold(counts[1:end], edges, Otsu())\n\nReference\n\nNobuyuki Otsu (1979). “A threshold selection method from gray-level histograms”. IEEE Trans. Sys., Man., Cyber. 9 (1): 62–66. doi:10.1109/TSMC.1979.4310076\n\n\n\n\n\n","category":"type"},{"location":"reference/#MinimumIntermodes","page":"Function Reference","title":"MinimumIntermodes","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"HistogramThresholding.MinimumIntermodes","category":"page"},{"location":"reference/#HistogramThresholding.MinimumIntermodes","page":"Function Reference","title":"HistogramThresholding.MinimumIntermodes","text":"t = find_threshold(histogram, edges, Minimum(); maxiter = 8000)\nt = find_threshold(img, Minimum(); nbins = 256)\n\nUnder the assumption that the histogram is bimodal the histogram is smoothed using a length-3 mean filter until two modes remain. The threshold is then set to the minimum value between the two modes.\n\nOutput\n\nReturns a real number t in edges. The edges parameter represents an AbstractRange which specifies the intervals associated with the histogram bins.\n\nExtended help\n\nDetails\n\nIf after maxiter iterations the smoothed histogram is still not bimodal then the algorithm will fall back to using the UnimodalRosin method to select a threshold.\n\nArguments\n\nThe function arguments are described in more detail below.\n\nhistogram\n\nAn AbstractArray storing the frequency distribution.\n\nedges\n\nAn AbstractRange specifying how the intervals for the frequency distribution are divided.\n\nmaxiter\n\nAn Int that specifies the maximum number of smoothing iterations. If left unspecified a default value of 8000 is used.\n\nExample\n\nCompute the threshold for the \"cameraman\" image in the TestImages package.\n\nusing TestImages, ImageContrastAdjustment, HistogramThresholding\n\nimg = testimage(\"cameraman\")\nedges, counts = build_histogram(img,256)\n#=\n  The `counts` array stores at index 0 the frequencies that were below the\n  first bin edge. Since we are seeking a threshold over the interval\n  partitioned by `edges` we need to discard the first bin in `counts`\n  so that the dimensions of `edges` and `counts` match.\n=#\nt = find_threshold(counts[1:end], edges, MinimumIntermodes())\n\nReference\n\nC. A. Glasbey, “An Analysis of Histogram-Based Thresholding Algorithms,” CVGIP: Graphical Models and Image Processing, vol. 55, no. 6, pp. 532–537, Nov. 1993. doi:10.1006/cgip.1993.1040\nJ. M. S. Prewitt and M. L. Mendelsohn, “THE ANALYSIS OF CELL IMAGES,” *Annals of the New York Academy of Sciences, vol. 128, no. 3, pp. 1035–1053, Dec. 2006. doi:10.1111/j.1749-6632.1965.tb11715.x\n\n\n\n\n\n","category":"type"},{"location":"reference/#Intermodes","page":"Function Reference","title":"Intermodes","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"HistogramThresholding.Intermodes","category":"page"},{"location":"reference/#HistogramThresholding.Intermodes","page":"Function Reference","title":"HistogramThresholding.Intermodes","text":"t = find_threshold(histogram, edges, Intermodes(maxiter=8000))\nt = find_threshold(img, Intermodes(); nbins = 256)\n\nUnder the assumption that the histogram is bimodal the histogram is smoothed using a length-3 mean filter until two modes remain. The threshold is then set to the average value of the two modes.\n\nOutput\n\nReturns a real number t in edges. The edges parameter represents an AbstractRange which specifies the intervals associated with the histogram bins.\n\nExtended help\n\nDetails\n\nIf after maxiter iterations the smoothed histogram is still not bimodal then the algorithm will fall back to using the UnimodalRosin method to select a threshold.\n\nArguments\n\nThe function arguments are described in more detail below.\n\nhistogram\n\nAn AbstractArray storing the frequency distribution.\n\nedges\n\nAn AbstractRange specifying how the intervals for the frequency distribution are divided.\n\nmaxiter\n\nAn Int that specifies the maximum number of smoothing iterations. If left unspecified a default value of 1000 is used.\n\nExample\n\nCompute the threshold for the \"cameraman\" image in the TestImages package.\n\n\nusing TestImages, ImageContrastAdjustment, HistogramThresholding\n\nimg = testimage(\"cameraman\")\nedges, counts = build_histogram(img,256)\n#=\n  The `counts` array stores at index 0 the frequencies that were below the\n  first bin edge. Since we are seeking a threshold over the interval\n  partitioned by `edges` we need to discard the first bin in `counts`\n  so that the dimensions of `edges` and `counts` match.\n=#\nt = find_threshold(counts[1:end], edges, Intermodes())\n\nReference\n\nC. A. Glasbey, “An Analysis of Histogram-Based Thresholding Algorithms,” CVGIP: Graphical Models and Image Processing, vol. 55, no. 6, pp. 532–537, Nov. 1993. doi:10.1006/cgip.1993.1040\n\n\n\n\n\n","category":"type"},{"location":"reference/#MinimumError","page":"Function Reference","title":"MinimumError","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"HistogramThresholding.MinimumError","category":"page"},{"location":"reference/#HistogramThresholding.MinimumError","page":"Function Reference","title":"HistogramThresholding.MinimumError","text":"t = find_threshold(histogram, edges, MinimumError())\nt = find_threshold(img, MinimumError(); nbins = 256)\n\nUnder the assumption that the histogram is a mixture of two Gaussian distributions the threshold is chosen such that the expected misclassification error rate is minimised.\n\nOutput\n\nReturns a real number t in edges. The edges parameter represents an AbstractRange which specifies the intervals associated with the histogram bins.\n\nExtended help\n\nDetails\n\nLet f_i (i=1 ldots I) denote the number of observations in the ith bin of the histogram. Then the probability that an observation belongs to the ith bin is given by  p_i = fracf_iN (i = 1 ldots I), where N = sum_i=1^If_i.\n\nThe minimum error thresholding method assumes that one can find a threshold T which partitions the data into two categories,  C_0 and C_1, such that the data can be modelled by a mixture of two Gaussian distribution. Let\n\nP_0(T) = sum_i = 1^T p_i quad textand quad P_1(T) = sum_i = T+1^I p_i\n\ndenote the cumulative probabilities,\n\nmu_0(T) = sum_i = 1^T i fracp_iP_0(T) quad textand quad mu_1(T) = sum_i = T+1^I i fracp_iP_1(T)\n\ndenote the means, and\n\nsigma_0^2(T) = sum_i = 1^T (i-mu_0(T))^2 fracp_iP_0(T) quad textand quad sigma_1^2(T) = sum_i = T+1^I (i-mu_1(T))^2 fracp_iP_1(T)\n\ndenote the variances of categories C_0 and C_1, respectively.\n\nKittler and Illingworth proposed to use the minimum error criterion function\n\nJ(T) = 1 + 2 left P_0(T) ln sigma_0(T) + P_1(T) ln sigma_1(T) right - 2 leftP_0(T) ln P_0(T) + P_1(T) ln P_1(T) right\n\nto assess the discreprancy between the mixture of Gaussians implied by a particular threshold T, and the piecewise-constant probability density function represented by the histogram. The discrete value T which minimizes the function J(T) produces the sought-after threshold value (i.e. the bin which determines the threshold).\n\nArguments\n\nThe function arguments are described in more detail below.\n\nhistogram\n\nAn AbstractArray storing the frequency distribution.\n\nedges\n\nAn AbstractRange specifying how the intervals for the frequency distribution are divided.\n\nExample\n\nCompute the threshold for the \"cameraman\" image in the TestImages package.\n\nusing TestImages, ImageContrastAdjustment, HistogramThresholding\n\nimg = testimage(\"cameraman\")\nedges, counts = build_histogram(img,256)\n#=\n  The `counts` array stores at index 0 the frequencies that were below the\n  first bin edge. Since we are seeking a threshold over the interval\n  partitioned by `edges` we need to discard the first bin in `counts`\n  so that the dimensions of `edges` and `counts` match.\n=#\nt = find_threshold(counts[1:end], edges, MinimumError())\n\nReferences\n\nJ. Kittler and J. Illingworth, “Minimum error thresholding,” Pattern Recognition, vol. 19, no. 1, pp. 41–47, Jan. 1986. doi:10.1016/0031-3203(86)90030-0\nQ.-Z. Ye and P.-E. Danielsson, “On minimum error thresholding and its implementations,” Pattern Recognition Letters, vol. 7, no. 4, pp. 201–206, Apr. 1988. doi:10.1016/0167-8655(88)90103-1\n\n\n\n\n\n","category":"type"},{"location":"reference/#Moments","page":"Function Reference","title":"Moments","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"HistogramThresholding.Moments","category":"page"},{"location":"reference/#HistogramThresholding.Moments","page":"Function Reference","title":"HistogramThresholding.Moments","text":"t = find_threshold(histogram, edges, Moments())\nt = find_threshold(img, Moments(); nbins = 256)\n\nThe following rule determines the threshold:  if one assigns all observations below the threshold to a value z₀ and all observations above the threshold to a value z₁, then the first three moments of the original histogram must match the moments of this specially constructed bilevel histogram.\n\nOutput\n\nReturns a real number t in edges. The edges parameter represents an AbstractRange which specifies the intervals associated with the histogram bins.\n\nExtended help\n\nDetails\n\nLet f_i (i=1 ldots I) denote the number of observations in the ith bin of the histogram and z_i (i=1 ldots I) the observed value associated with the ith bin.  Then the probability that an observation z_i belongs to the ith bin is given by  p_i = fracf_iN (i = 1 ldots I), where N = sum_i=1^If_i.\n\nMoments can be computed from the histogram f in the following way:\n\nm_k = frac1N sum_i p_i (z_i)^k quad k = 0123 ldots\n\nThe principle of moment-preserving thresholding is to select a threshold value, as well as two representative values z_0 and z_1 (z_0  z_1), such that if all below-threshold values in f are replaced by z_0 and all above-threshold values are replaced by z_1, then this specially constructed bilevel histogram g will have the same first three moments as f.\n\nConcretely, let q_0 and q_1 denote the fractions of observations below and above the threshold in f, respectively. The constraint that the first three moments in g must equal the first three moments in f can be expressed by the following system of four equations\n\nbeginaligned\n   q_0 (z_0)^0 + q_1 (z_1)^0    = m_0 \n   q_0 (z_0)^1 + q_1 (z_1)^1    = m_1 \n   q_0 (z_0)^2 + q_1 (z_1)^2    = m_2 \n   q_0 (z_0)^3 + q_1 (z_1)^3    = m_3 \nendaligned\n\nwhere the left-hand side represents the moments of g and the right-hand side represents the moments of f. To find the desired treshold value, one first solves the four equations to obtain q_0 and q_1, and then chooses the threshold t such that q_0 = sum_z_i le t p_i.\n\nArguments\n\nThe function arguments are described in more detail below.\n\nhistogram\n\nAn AbstractArray storing the frequency distribution.\n\nedges\n\nAn AbstractRange specifying how the intervals for the frequency distribution are divided.\n\nExample\n\nCompute the threshold for the \"cameraman\" image in the TestImages package.\n\nusing TestImages, ImageContrastAdjustment, HistogramThresholding\n\nimg = testimage(\"cameraman\")\nedges, counts = build_histogram(img,256)\n#=\n  The `counts` array stores at index 0 the frequencies that were below the\n  first bin edge. Since we are seeking a threshold over the interval\n  partitioned by `edges` we need to discard the first bin in `counts`\n  so that the dimensions of `edges` and `counts` match.\n=#\nt = find_threshold(counts[1:end], edges, Moments())\n\nReference\n\n[1] W.-H. Tsai, “Moment-preserving thresolding: A new approach,” Computer Vision, Graphics, and Image Processing, vol. 29, no. 3, pp. 377–393, Mar. 1985. doi:10.1016/0734-189x(85)90133-1\n\n\n\n\n\n","category":"type"},{"location":"reference/#UnimodalRosin","page":"Function Reference","title":"UnimodalRosin","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"HistogramThresholding.UnimodalRosin","category":"page"},{"location":"reference/#HistogramThresholding.UnimodalRosin","page":"Function Reference","title":"HistogramThresholding.UnimodalRosin","text":"t = find_threshold(histogram, edges, UnimodalRosin())\nt = find_threshold(img, UnimodalRosin(); nbins = 256)\n\nGenerates a threshold assuming a unimodal distribution using Rosin's algorithm.\n\nOutput\n\nReturns a real number t in edges. The edges parameter represents an AbstractRange which specifies the intervals associated with the histogram bins.\n\nExtended help\n\nDetails\n\nThis algorithm first selects the bin in the histogram with the highest frequency. The algorithm then searches from the location of the maximum bin to the last bin of the histogram for the first bin with a frequency of 0 (known as the minimum bin.). A line is then drawn that passes through both the maximum and minimum bins. The bin with the greatest orthogonal distance to the line is chosen as the threshold value.\n\nAssumptions\n\nThis algorithm assumes that:\n\nThe histogram is unimodal.\nThere is always at least one bin that has a frequency of 0. If not, the algorithm will use the last bin as the minimum bin.\n\nIf the histogram includes multiple bins with a frequency of 0, the algorithm will select the first zero bin as its minimum. If there are multiple bins with the greatest orthogonal distance, the leftmost bin is selected as the threshold.\n\nArguments\n\nThe function arguments are described in more detail below.\n\nhistogram\n\nAn AbstractArray storing the frequency distribution.\n\nedges\n\nAn AbstractRange specifying how the intervals for the frequency distribution are divided.\n\nExample\n\nCompute the threshold for the \"moonsurface\" image in the TestImages package.\n\nusing TestImages, ImageContrastAdjustment, HistogramThresholding\n\nimg = testimage(\"moonsurface\")\nedges, counts = build_histogram(img,256)\n#=\n  The `counts` array stores at index 0 the frequencies that were below the\n  first bin edge. Since we are seeking a threshold over the interval\n  partitioned by `edges` we need to discard the first bin in `counts`\n  so that the dimensions of `edges` and `counts` match.\n=#\nt = find_threshold(counts[1:end], edges, UnimodalRosin())\n\nReference\n\nP. L. Rosin, “Unimodal thresholding,” Pattern Recognition, vol. 34, no. 11, pp. 2083–2096, Nov. 2001.doi:10.1016/s0031-3203(00)00136-9\n\n\n\n\n\n","category":"type"},{"location":"reference/#Entropy","page":"Function Reference","title":"Entropy","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"HistogramThresholding.Entropy","category":"page"},{"location":"reference/#HistogramThresholding.Entropy","page":"Function Reference","title":"HistogramThresholding.Entropy","text":"find_threshold(counts, edges, Entropy())\nt = find_threshold(img, Entropy(); nbins = 256)\n\nAn algorithm for finding the threshold value for a gray-level histogram using the entropy of the histogram.\n\nOutput\n\nReturns the point in the AbstractRange which corresponds to the threshold bin in the histogram.\n\nExtended help\n\nDetails\n\nThis algorithm uses the entropy of a gray level histogram to produce a threshold value.\n\nLet f_1 f_2 ldots f_I be the frequencies in the various bins of the histogram and I the number of bins. With N = sum_i=1^If_i, let p_i = fracf_iN (i = 1 ldots I) denote the probability distribution of gray levels. From this distribution one derives two additional distributions. The first defined for discrete values 1 to s and the other, from s+1 to I. These distributions are\n\nA fracp_1P_s fracp_2P_s ldots fracp_sP_s\nquad textand quad\nB fracp_s+11-P_s ldots fracp_n1-P_s\nquad textwhere quad\nP_s = sum_i=1^sp_i\n\nThe entropies associated with each distribution are as follows:\n\nH(A) = ln(P_s) + fracH_sP_s\n\nH(B) = ln(1-P_s) + fracH_n-H_s1-P_s\n\nquad textwhere quad\nH_s = -sum_i=1^sp_ilnp_i\nquad textand quad\nH_n = -sum_i=1^Ip_ilnp_i\n\nCombining these two entropy functions we have\n\npsi(s) = ln(P_s(1-P_s)) + fracH_sP_s + fracH_n-H_s1-P_s\n\nFinding the discrete value s which maximises the function psi(s) produces the sought-after threshold value (i.e. the bin which determines the threshold).\n\nSee Section 4 of [1] for more details on the derivation of the entropy.\n\nOptions\n\nChoices for counts\n\nYou can specify an AbstractArray which should be a 1D array of frequencies for a histogram. You should submit the corresponding edges range for the bins of the histogram. The function will throw an error if it detects that the edges and counts have different lengths.\n\nChoices for edges\n\nYou can specify an AbstractRange which should be the corresponding range for the bins of the histogram array passed into counts.\n\nExample\n\n\nusing TestImages, Images\n\nimg = testimage(\"cameraman\")\n# building a histogram with 256 bins\nedges, counts = build_histogram(img, 256)\n#=\n  The `counts` array stores at index 0 the frequencies that were below the\n  first bin edge. Since we are seeking a threshold over the interval\n  partitioned by `edges` we need to discard the first bin in `counts`\n  so that the dimensions of `edges` and `counts` match.\n=#\nfind_threshold(counts[1:end], edges, Entropy())\n\nReferences\n\n[1] J. N. Kapur, P. K. Sahoo, and A. K. C. Wong, “A new method for gray-level picture thresholding using the entropy of the histogram,” Computer Vision, Graphics, and Image Processing, vol. 29, no. 1, p. 140, Jan. 1985.doi:10.1016/s0734-189x(85)90156-2\n\n\n\n\n\n","category":"type"},{"location":"reference/#Balanced","page":"Function Reference","title":"Balanced","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"HistogramThresholding.Balanced","category":"page"},{"location":"reference/#HistogramThresholding.Balanced","page":"Function Reference","title":"HistogramThresholding.Balanced","text":"t = find_threshold(histogram, edges, Balanced())\nt = find_threshold(img, Balanced(); nbins = 256)\n\nIn balanced histogram thresholding, one interprets a  bin as a  physical weight with a mass equal to its occupancy count. The balanced histogram method involves iterating the following three steps: (1) choose the midpoint bin index as a \"pivot\",  (2) compute the combined weight to the left and right of the pivot bin and (3) remove the leftmost bin if the left side is the heaviest, and the rightmost bin otherwise. The algorithm stops when only a single bin remains. The last bin determines the sought-after threshold.\n\nOutput\n\nReturns a real number t in edges. The edges parameter represents an AbstractRange which specifies the intervals associated with the histogram bins.\n\nExtended help\n\nDetails\n\nLet f_n (n = 1 ldots N) denote the number of observations in the nth bin of the histogram. The balanced histogram method constructs a sequence of nested intervals\n\n1N cap mathbbZ supset I_2 supset I_3 supset ldots supset I_N-1\n\nwhere for k = 2 ldots N-1\n\nI_k = begincases\n   I_k-1 setminus min left( I_k-1 right)  textif  sum_n = min left( I_k-1 right)^I_mf_n gt   sum_n =  I_m + 1^ max left( I_k-1 right) f_n \r\n   I_k-1 setminus max left( I_k-1 right)  textotherwise\nendcases\n\nand I_m = lfloor frac12left(  min left( I_k-1 right) +  max left( I_k-1 right) right) rfloor. The final interval I_N-1 consists of a single element which is the bin index corresponding to the desired threshold.\n\nIf one interprets a bin as a physical weight with a mass equal to its occupancy count, then each step of the algorithm can be conceptualised as removing the leftmost or rightmost bin to \"balance\" the resulting histogram on a pivot. The pivot is defined to be the midpoint between the start and end points of the interval under consideration.\n\nIf it turns out that the single element in I_N-1 equals 1 or N then the original histogram must have a single peak and the algorithm has failed to find a suitable threshold. In this case the algorithm will fall back to using the UnimodalRosin method to select the threshold.\n\nArguments\n\nThe function arguments are described in more detail below.\n\nhistogram\n\nAn AbstractArray storing the frequency distribution.\n\nedges\n\nAn AbstractRange specifying how the intervals for the frequency distribution are divided.\n\nExample\n\nCompute the threshold for the \"cameraman\" image in the TestImages package.\n\n\nusing TestImages, ImageContrastAdjustment, HistogramThresholding\n\nimg = testimage(\"cameraman\")\nedges, counts = build_histogram(img, 256)\n#=\n  The `counts` array stores at index 0 the frequencies that were below the\n  first bin edge. Since we are seeking a threshold over the interval\n  partitioned by `edges` we need to discard the first bin in `counts`\n  so that the dimensions of `edges` and `counts` match.\n=#\nt = find_threshold(counts[1:end], edges, Balanced())\n\nReference\n\n“BI-LEVEL IMAGE THRESHOLDING - A Fast Method”, Proceedings of the First International Conference on Bio-inspired Systems and Signal Processing, 2008. Available: 10.5220/0001064300700076\n\n\n\n\n\n","category":"type"},{"location":"reference/#Yen","page":"Function Reference","title":"Yen","text":"","category":"section"},{"location":"reference/","page":"Function Reference","title":"Function Reference","text":"HistogramThresholding.Yen","category":"page"},{"location":"reference/#HistogramThresholding.Yen","page":"Function Reference","title":"HistogramThresholding.Yen","text":"t = find_threshold(histogram, edges, Yen())\nt = find_threshold(img, Yen(); nbins = 256)\n\nComputes the threshold value using Yen's maximum correlation criterion for bilevel thresholding.\n\nOutput\n\nReturns a real number t in edges. The edges parameter represents an AbstractRange which specifies the intervals associated with the histogram bins.\n\nExtended help\n\nDetails\n\nThis algorithm uses the concept of entropic correlation of a gray level histogram to produce a threshold value.\n\nLet f_1 f_2 ldots f_I be the frequencies in the various bins of the histogram and I the number of bins. With N = sum_i=1^If_i, let p_i = fracf_iN (i = 1 ldots I) denote the probability distribution of gray levels. From this distribution one derives two additional distributions. The first defined for discrete values 1 to s and the other, from s+1 to I. These distributions are\n\nA fracp_1P_s fracp_2P_s ldots fracp_sP_s\nquad textand quad\nB fracp_s+11-P_s ldots fracp_n1-P_s\nquad textwhere quad\nP_s = sum_i=1^sp_i\n\nThe entropic correlations associated with each distribution are\n\nC(A) = -ln sum_i=1^s left( fracp_iP_s right)^2 quad textand quad C(B) = -ln sum_i=s+1^I left( fracp_i1 - P_s right)^2\n\nCombining these two entropic correlation functions we have\n\npsi(s) = -ln sum_i=1^s left( fracp_iP_s right)^2 -ln sum_i=s+1^I left( fracp_i1 - P_s right)^2\n\nFinding the discrete value s which maximises the function psi(s) produces the sought-after threshold value (i.e. the bin which determines the threshold).\n\nArguments\n\nThe function arguments are described in more detail below.\n\nhistogram\n\nAn AbstractArray storing the frequency distribution.\n\nedges\n\nAn AbstractRange specifying how the intervals for the frequency distribution are divided.\n\nExample\n\nCompute the threshold for the \"cameraman\" image in the TestImages package.\n\n\nusing TestImages, ImageContrastAdjustment, HistogramThresholding\n\nimg = testimage(\"cameraman\")\nedges, counts = build_histogram(img, 256)\n#=\n  The `counts` array stores at index 0 the frequencies that were below the\n  first bin edge. Since we are seeking a threshold over the interval\n  partitioned by `edges` we need to discard the first bin in `counts`\n  so that the dimensions of `edges` and `counts` match.\n=#\nt = find_threshold(counts[1:end], edges, Yen())\n\nReference\n\nYen JC, Chang FJ, Chang S (1995), “A New Criterion for Automatic Multilevel Thresholding”, IEEE Trans. on Image Processing 4 (3): 370-378, doi:10.1109/83.366472\n\n\n\n\n\n","category":"type"},{"location":"#ImageBinarization.jl-Documentation","page":"Home","title":"ImageBinarization.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A Julia package containing a number of algorithms for analyzing images and automatically binarizing them into background and foreground.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Depth = 3","category":"page"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package is part of a wider Julia-based image processing ecosystem. If you are starting out, then you may benefit from reading about some fundamental conventions that the ecosystem utilizes that are markedly different from how images are typically represented in OpenCV, MATLAB, ImageJ or Python.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The usage examples in the ImageBinarization.jl package assume that you have already installed some key packages. Notably, the examples assume that you are able to load and display an image. Loading an image is facilitated through the FileIO.jl package, which uses QuartzImageIO.jl if you are on MacOS, and ImageMagick.jl otherwise. Depending on your particular system configuration, you might encounter problems installing the image loading packages, in which case you can refer to the troubleshooting guide.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Image display is typically handled by the ImageView.jl package. Alternatives include the various plotting packages, including Makie.jl. There is also the ImageShow.jl package which facilitates displaying images in Jupyter notebooks via IJulia.jl. Finally, one can also obtain a useful preview of an image in the REPL using the ImageInTerminal.jl package. However, this package assumes that the terminal uses a monospace font, and tends not to produce adequate results in a Windows environment.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Another package that is used to illustrate the functionality in ImageBinarization.jl is the TestImages.jl which serves as a repository of many standard image processing test images.","category":"page"},{"location":"#Basic-usage","page":"Home","title":"Basic usage","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Each binarization algorithm in ImageBinarization.jl is an AbstractImageBinarizationAlgorithm.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Suppose one wants to binarize an image. This can be achieved by simply choosing an appropriate algorithm and calling binarize or binarize! in the image. The background and foreground will be automatically binarized.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Let's see a simple demo:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using TestImages, ImageBinarization\nusing FileIO # hide\nimg = testimage(\"cameraman\")\nalg = Otsu()\nimg₀₁ = binarize(img, alg)\nsave(\"images/demo.jpg\", hcat(img, img₀₁)) # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"<img src=\"images/demo.jpg\" width=\"400px\" alt=\"demo image\" />","category":"page"},{"location":"","page":"Home","title":"Home","text":"This usage reads as \"binarize the image img with algorithm alg\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"For more advanced usage, please check function reference page.","category":"page"},{"location":"#Examples-of-ImageBinarization-in-action","page":"Home","title":"Examples of ImageBinarization in action","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"<h>Image of cells:</h>\n<table width=\"500\" border=\"0\" cellpadding=\"5\">\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/cells.jpg\" width=\"100px\" alt=\"Original image\" />\n<br />\nOriginal image\n</td>\n</tr>\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/cells_Intermodes.jpg\" width=\"100px\" alt=\"Intermodes\" />\n<br />\nIntermodes\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/cells_MinimumError.jpg\" width=\"100px\" alt=\"Minimum Error\" />\n<br />\nMinimum Error\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/cells_MinimumIntermodes.jpg\" width=\"100px\" alt=\"Minimum\" />\n<br />\nMinimum\n</td>\n</tr>\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/cells_Moments.jpg\" width=\"100px\" alt=\"Moments\" />\n<br />\nMoments\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/cells_otsu.jpg\" width=\"100px\" alt=\"Otsu\" />\n<br />\nOtsu\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/cells_Polysegment.jpg\" width=\"100px\" alt=\"Polysegment\" />\n<br />\nPolysegment\n</td>\n</tr>\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/cells_UnimodalRosin.jpg\" width=\"100px\" alt=\"Rosin\" />\n<br />\nRosin\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/cells_sauvola.png\" width=\"100px\" alt=\"Sauvola\" />\n<br />\nSauvola\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/cells_niblack.png\" width=\"100px\" alt=\"Niblack\" />\n<br />\nNiblack\n</td>\n</tr>\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/cells_Adaptive.jpg\" width=\"100px\" alt=\"Adaptive\" />\n<br />\nAdaptive\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/cells_Yen.jpg\" width=\"100px\" alt=\"Yen\" />\n<br />\nYen\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/cells_Balanced.jpg\" width=\"100px\" alt=\"Balanced\" />\n<br />\nBalanced\n</td>\n</tr>\n</table>\n\n<h>Image of moon surface: (Unimodal)</h>\n<table width=\"500\" border=\"0\" cellpadding=\"5\">\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/moon.jpg\" width=\"100px\" alt=\"Original image\" />\n<br />\nOriginal image\n</td>\n</tr>\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/moon_Intermodes.jpg\" width=\"100px\" alt=\"Intermodes\" />\n<br />\nIntermodes\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/moon_MinimumError.jpg\" width=\"100px\" alt=\"Minimum Error\" />\n<br />\nMinimum Error\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/moon_MinimumIntermodes.jpg\" width=\"100px\" alt=\"Minimum\" />\n<br />\nMinimum\n</td>\n</tr>\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/moon_Moments.jpg\" width=\"100px\" alt=\"Moments\" />\n<br />\nMoments\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/moon_otsu.jpg\" width=\"100px\" alt=\"Otsu\" />\n<br />\nOtsu\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/moon_Polysegment.jpg\" width=\"100px\" alt=\"Polysegment\" />\n<br />\nPolysegment\n</td>\n</tr>\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/moon_UnimodalRosin.jpg\" width=\"100px\" alt=\"Rosin\" />\n<br />\nRosin\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/moon_sauvola.png\" width=\"100px\" alt=\"Sauvola\" />\n<br />\nSauvola\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/moon_niblack.png\" width=\"100px\" alt=\"Niblack\" />\n<br />\nNiblack\n</td>\n</tr>\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/moon_Adaptive.jpg\" width=\"100px\" alt=\"Adaptive\" />\n<br />\nAdaptive\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/moon_Yen.jpg\" width=\"100px\" alt=\"Yen\" />\n<br />\nYen\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/moon_Balanced.jpg\" width=\"100px\" alt=\"Balanced\" />\n<br />\nBalanced\n</td>\n</tr>\n</table>\n\n<h>Image of text:</h>\n<table width=\"500\" border=\"0\" cellpadding=\"5\">\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/page.jpg\" width=\"100px\" alt=\"Original image\" />\n<br />\nOriginal image\n</td>\n</tr>\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/page_Intermodes.jpg\" width=\"100px\" alt=\"Intermodes\" />\n<br />\nIntermodes\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/page_MinimumError.jpg\" width=\"100px\" alt=\"Minimum Error\" />\n<br />\nMinimum Error\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/page_MinimumIntermodes.jpg\" width=\"100px\" alt=\"Minimum\" />\n<br />\nMinimum\n</td>\n</tr>\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/page_Moments.jpg\" width=\"100px\" alt=\"Moments\" />\n<br />\nMoments\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/page_otsu.jpg\" width=\"100px\" alt=\"Otsu\" />\n<br />\nOtsu\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/page_Polysegment.jpg\" width=\"100px\" alt=\"Polysegment\" />\n<br />\nPolysegment\n</td>\n</tr>\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/page_UnimodalRosin.jpg\" width=\"100px\" alt=\"Rosin\" />\n<br />\nRosin\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/page_sauvola.png\" width=\"100px\" alt=\"Sauvola\" />\n<br />\nSauvola\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/page_niblack.png\" width=\"100px\" alt=\"Niblack\" />\n<br />\nNiblack\n</td>\n</tr>\n\n<tr>\n<td align=\"center\" valign=\"center\">\n<img src=\"images/page_Adaptive.jpg\" width=\"100px\" alt=\"Adaptive\" />\n<br />\nAdaptive\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/page_Yen.jpg\" width=\"100px\" alt=\"yen\" />\n<br />\nYen\n</td>\n\n<td align=\"center\" valign=\"center\">\n<img src=\"images/page_Balanced.jpg\" width=\"100px\" alt=\"Balanced\" />\n<br />\nBalanced\n</td>\n</tr>\n</table>","category":"page"}]
}
